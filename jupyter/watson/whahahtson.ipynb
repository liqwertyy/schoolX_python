{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import nltk.tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>lang_abv</th>\n",
       "      <th>language</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5130fd2cb5</td>\n",
       "      <td>and these comments were considered in formulat...</td>\n",
       "      <td>The rules developed in the interim were put to...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b72532a0b</td>\n",
       "      <td>These are issues that we wrestle with in pract...</td>\n",
       "      <td>Practice groups are not permitted to work on t...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3931fbe82a</td>\n",
       "      <td>Des petites choses comme celles-là font une di...</td>\n",
       "      <td>J'essayais d'accomplir quelque chose.</td>\n",
       "      <td>fr</td>\n",
       "      <td>French</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5622f0c60b</td>\n",
       "      <td>you know they can't really defend themselves l...</td>\n",
       "      <td>They can't defend themselves because of their ...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86aaa48b45</td>\n",
       "      <td>ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...</td>\n",
       "      <td>เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร</td>\n",
       "      <td>th</td>\n",
       "      <td>Thai</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12115</th>\n",
       "      <td>2b78e2a914</td>\n",
       "      <td>The results of even the most well designed epi...</td>\n",
       "      <td>All studies have the same amount of uncertaint...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12116</th>\n",
       "      <td>7e9943d152</td>\n",
       "      <td>But there are two kinds of  the pleasure of do...</td>\n",
       "      <td>But there are two kinds of the pleasure of doi...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12117</th>\n",
       "      <td>5085923e6c</td>\n",
       "      <td>The important thing is to realize that it's wa...</td>\n",
       "      <td>It cannot be moved, now or ever.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>fc8e2fd1fe</td>\n",
       "      <td>At the west end is a detailed model of the who...</td>\n",
       "      <td>The model temple complex is at the east end.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12119</th>\n",
       "      <td>44301dfb14</td>\n",
       "      <td>For himself he chose Atat??rk, or Father of th...</td>\n",
       "      <td>Ataturk was the father of the Turkish nation.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                            premise  \\\n",
       "0      5130fd2cb5  and these comments were considered in formulat...   \n",
       "1      5b72532a0b  These are issues that we wrestle with in pract...   \n",
       "2      3931fbe82a  Des petites choses comme celles-là font une di...   \n",
       "3      5622f0c60b  you know they can't really defend themselves l...   \n",
       "4      86aaa48b45  ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...   \n",
       "...           ...                                                ...   \n",
       "12115  2b78e2a914  The results of even the most well designed epi...   \n",
       "12116  7e9943d152  But there are two kinds of  the pleasure of do...   \n",
       "12117  5085923e6c  The important thing is to realize that it's wa...   \n",
       "12118  fc8e2fd1fe  At the west end is a detailed model of the who...   \n",
       "12119  44301dfb14  For himself he chose Atat??rk, or Father of th...   \n",
       "\n",
       "                                              hypothesis lang_abv language  \\\n",
       "0      The rules developed in the interim were put to...       en  English   \n",
       "1      Practice groups are not permitted to work on t...       en  English   \n",
       "2                  J'essayais d'accomplir quelque chose.       fr   French   \n",
       "3      They can't defend themselves because of their ...       en  English   \n",
       "4        เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร       th     Thai   \n",
       "...                                                  ...      ...      ...   \n",
       "12115  All studies have the same amount of uncertaint...       en  English   \n",
       "12116  But there are two kinds of the pleasure of doi...       en  English   \n",
       "12117                   It cannot be moved, now or ever.       en  English   \n",
       "12118       The model temple complex is at the east end.       en  English   \n",
       "12119      Ataturk was the father of the Turkish nation.       en  English   \n",
       "\n",
       "       label  \n",
       "0          0  \n",
       "1          2  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  \n",
       "...      ...  \n",
       "12115      2  \n",
       "12116      0  \n",
       "12117      2  \n",
       "12118      2  \n",
       "12119      0  \n",
       "\n",
       "[12120 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = pd.read_csv(\"./train.csv\")\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>language</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and these comments were considered in formulat...</td>\n",
       "      <td>The rules developed in the interim were put to...</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>These are issues that we wrestle with in pract...</td>\n",
       "      <td>Practice groups are not permitted to work on t...</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Des petites choses comme celles-là font une di...</td>\n",
       "      <td>J'essayais d'accomplir quelque chose.</td>\n",
       "      <td>French</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you know they can't really defend themselves l...</td>\n",
       "      <td>They can't defend themselves because of their ...</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...</td>\n",
       "      <td>เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร</td>\n",
       "      <td>Thai</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12115</th>\n",
       "      <td>The results of even the most well designed epi...</td>\n",
       "      <td>All studies have the same amount of uncertaint...</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12116</th>\n",
       "      <td>But there are two kinds of  the pleasure of do...</td>\n",
       "      <td>But there are two kinds of the pleasure of doi...</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12117</th>\n",
       "      <td>The important thing is to realize that it's wa...</td>\n",
       "      <td>It cannot be moved, now or ever.</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>At the west end is a detailed model of the who...</td>\n",
       "      <td>The model temple complex is at the east end.</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12119</th>\n",
       "      <td>For himself he chose Atat??rk, or Father of th...</td>\n",
       "      <td>Ataturk was the father of the Turkish nation.</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 premise  \\\n",
       "0      and these comments were considered in formulat...   \n",
       "1      These are issues that we wrestle with in pract...   \n",
       "2      Des petites choses comme celles-là font une di...   \n",
       "3      you know they can't really defend themselves l...   \n",
       "4      ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...   \n",
       "...                                                  ...   \n",
       "12115  The results of even the most well designed epi...   \n",
       "12116  But there are two kinds of  the pleasure of do...   \n",
       "12117  The important thing is to realize that it's wa...   \n",
       "12118  At the west end is a detailed model of the who...   \n",
       "12119  For himself he chose Atat??rk, or Father of th...   \n",
       "\n",
       "                                              hypothesis language  label  \n",
       "0      The rules developed in the interim were put to...  English      0  \n",
       "1      Practice groups are not permitted to work on t...  English      2  \n",
       "2                  J'essayais d'accomplir quelque chose.   French      0  \n",
       "3      They can't defend themselves because of their ...  English      0  \n",
       "4        เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร     Thai      1  \n",
       "...                                                  ...      ...    ...  \n",
       "12115  All studies have the same amount of uncertaint...  English      2  \n",
       "12116  But there are two kinds of the pleasure of doi...  English      0  \n",
       "12117                   It cannot be moved, now or ever.  English      2  \n",
       "12118       The model temple complex is at the east end.  English      2  \n",
       "12119      Ataturk was the father of the Turkish nation.  English      0  \n",
       "\n",
       "[12120 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndt = dt.drop(['id','lang_abv'],axis=1)\n",
    "ndt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>language</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and these comments were considered in formulat...</td>\n",
       "      <td>The rules developed in the interim were put to...</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>These are issues that we wrestle with in pract...</td>\n",
       "      <td>Practice groups are not permitted to work on t...</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you know they can't really defend themselves l...</td>\n",
       "      <td>They can't defend themselves because of their ...</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>From Cockpit Country to St. Ann's Bay</td>\n",
       "      <td>From St. Ann's Bay to Cockpit Country.</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Look, it's your skin, but you're going to be i...</td>\n",
       "      <td>The boss will fire you if he sees you slacking...</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12115</th>\n",
       "      <td>The results of even the most well designed epi...</td>\n",
       "      <td>All studies have the same amount of uncertaint...</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12116</th>\n",
       "      <td>But there are two kinds of  the pleasure of do...</td>\n",
       "      <td>But there are two kinds of the pleasure of doi...</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12117</th>\n",
       "      <td>The important thing is to realize that it's wa...</td>\n",
       "      <td>It cannot be moved, now or ever.</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>At the west end is a detailed model of the who...</td>\n",
       "      <td>The model temple complex is at the east end.</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12119</th>\n",
       "      <td>For himself he chose Atat??rk, or Father of th...</td>\n",
       "      <td>Ataturk was the father of the Turkish nation.</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6870 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 premise  \\\n",
       "0      and these comments were considered in formulat...   \n",
       "1      These are issues that we wrestle with in pract...   \n",
       "3      you know they can't really defend themselves l...   \n",
       "7                  From Cockpit Country to St. Ann's Bay   \n",
       "8      Look, it's your skin, but you're going to be i...   \n",
       "...                                                  ...   \n",
       "12115  The results of even the most well designed epi...   \n",
       "12116  But there are two kinds of  the pleasure of do...   \n",
       "12117  The important thing is to realize that it's wa...   \n",
       "12118  At the west end is a detailed model of the who...   \n",
       "12119  For himself he chose Atat??rk, or Father of th...   \n",
       "\n",
       "                                              hypothesis language  label  \n",
       "0      The rules developed in the interim were put to...  English      0  \n",
       "1      Practice groups are not permitted to work on t...  English      2  \n",
       "3      They can't defend themselves because of their ...  English      0  \n",
       "7                 From St. Ann's Bay to Cockpit Country.  English      2  \n",
       "8      The boss will fire you if he sees you slacking...  English      1  \n",
       "...                                                  ...      ...    ...  \n",
       "12115  All studies have the same amount of uncertaint...  English      2  \n",
       "12116  But there are two kinds of the pleasure of doi...  English      0  \n",
       "12117                   It cannot be moved, now or ever.  English      2  \n",
       "12118       The model temple complex is at the east end.  English      2  \n",
       "12119      Ataturk was the father of the Turkish nation.  English      0  \n",
       "\n",
       "[6870 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_of_sevens = (dt['language'] == \"English\").sum()\n",
    "df = ndt[ndt['language'] == 'English']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['premise','hypothesis']]\n",
    "y = df[['label']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Приведение к нижнему регистру\n",
    "    text = text.lower()\n",
    "    # Удаление пунктуации\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Токенизация\n",
    "    tokens = word_tokenize(text)\n",
    "    # Удаление стоп-слов\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Объединение токенов обратно в текст\n",
    "    processed_text = ' '.join(tokens)\n",
    "    return processed_text\n",
    "\n",
    "# Применение предобработки ко всей колонке\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8611</th>\n",
       "      <td>There are many homes built into the hillsides;...</td>\n",
       "      <td>The remaining homes that have not been convert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9396</th>\n",
       "      <td>Each of them was as tough as a thick tree and ...</td>\n",
       "      <td>They were tough and loyal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>i understand i can imagine you all have much t...</td>\n",
       "      <td>yes, up there the insects must be really annoy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2630</th>\n",
       "      <td>However, the other young lady was most kind.</td>\n",
       "      <td>I was told to leave immediately by the other y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>well what is it</td>\n",
       "      <td>Don't tell me about it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>HE KNOWS ABOUT THE MINES.</td>\n",
       "      <td>He has no idea that the mines exist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9609</th>\n",
       "      <td>If I had chosen to be an actor, I should have ...</td>\n",
       "      <td>I did not choose to become an actor, as at the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11457</th>\n",
       "      <td>At the top of the hill is the imposing medieva...</td>\n",
       "      <td>The medieval castle of Kadifekale is located a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11580</th>\n",
       "      <td>She admits to Dorcas, 'I don't know what to do...</td>\n",
       "      <td>She did not admit anything while speaking to D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9382</th>\n",
       "      <td>The narthex, or entrance hall to the nave, is ...</td>\n",
       "      <td>There is a tympanum of Jesus above the entranc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1374 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 premise  \\\n",
       "8611   There are many homes built into the hillsides;...   \n",
       "9396   Each of them was as tough as a thick tree and ...   \n",
       "3954   i understand i can imagine you all have much t...   \n",
       "2630       However, the other young lady was most kind.    \n",
       "4433                                     well what is it   \n",
       "...                                                  ...   \n",
       "8120                           HE KNOWS ABOUT THE MINES.   \n",
       "9609   If I had chosen to be an actor, I should have ...   \n",
       "11457  At the top of the hill is the imposing medieva...   \n",
       "11580  She admits to Dorcas, 'I don't know what to do...   \n",
       "9382   The narthex, or entrance hall to the nave, is ...   \n",
       "\n",
       "                                              hypothesis  \n",
       "8611   The remaining homes that have not been convert...  \n",
       "9396                          They were tough and loyal.  \n",
       "3954   yes, up there the insects must be really annoy...  \n",
       "2630   I was told to leave immediately by the other y...  \n",
       "4433                             Don't tell me about it.  \n",
       "...                                                  ...  \n",
       "8120               He has no idea that the mines exist.   \n",
       "9609   I did not choose to become an actor, as at the...  \n",
       "11457  The medieval castle of Kadifekale is located a...  \n",
       "11580  She did not admit anything while speaking to D...  \n",
       "9382   There is a tympanum of Jesus above the entranc...  \n",
       "\n",
       "[1374 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.local/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/andrew/.local/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5496,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "label_encoder = LabelEncoder()\n",
    "X_train['fit'] = (X_train['premise'] + ' ' + X_train['hypothesis']).apply(preprocess_text)\n",
    "X_test['fit'] = (X_test['premise'] + ' ' + X_test['hypothesis']).apply(preprocess_text)\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['fit'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['fit'])\n",
    "y_train_encoded = label_encoder.fit_transform(y_train) # one-hot encoder\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_train_encoded.shape # должен быть (5496, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4288.6714)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)\n",
    "X_train_tensor = torch.tensor(X_train_tfidf.toarray(), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_tfidf.toarray(), dtype=torch.float32)\n",
    "X_train_tensor.sum()\n",
    "X_test_tensor.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 100\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 18)\n",
    "        self.fc2 = nn.Linear(18, 30)\n",
    "        self.fc3 = nn.Linear(30, 25)\n",
    "        self.fc4 = nn.Linear(25, 12)\n",
    "        self.fc5 = nn.Linear(12, output_size)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in (self.fc1, self.fc2, self.fc3, self.fc4, self.fc5):\n",
    "            x = i(x)\n",
    "            x = nn.Softmax()(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextClassifier(input_size=X_train_tensor.shape[1],\n",
    "                       output_size=len(label_encoder.classes_))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0990, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1007, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1053, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1104, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0984, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1026, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1052, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1013, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1002, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1026, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1097, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1081, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1029, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0975, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0987, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0958, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0979, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1090, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0945, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1063, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1029, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1048, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1106, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1050, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0968, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0939, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0960, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1101, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1026, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1104, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1122, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1008, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1026, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1054, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0950, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1090, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1011, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0985, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0989, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1058, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0977, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1027, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1097, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1116, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1029, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1024, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1130, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1085, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1053, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1089, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1011, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0975, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1098, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0963, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1054, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1063, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1058, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1074, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0904, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1104, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0972, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1152, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1117, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1126, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1072, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1053, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1119, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1113, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0926, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1098, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0944, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1004, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0968, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1018, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1038, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1117, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1086, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0998, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1117, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1096, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0997, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0949, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0977, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0968, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1075, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1052, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0987, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1019, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1071, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0927, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1096, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1166, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1194, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1135, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1004, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0958, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1062, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1129, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1002, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0901, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1080, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1106, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1113, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1066, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0895, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1066, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0901, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1050, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0960, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1162, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1003, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1011, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0998, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1114, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0984, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1016, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1080, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0945, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1007, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1061, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1084, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1026, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1136, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1093, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0940, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0946, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1060, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1055, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1013, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1065, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0941, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1030, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0960, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1027, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1065, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1093, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1060, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1083, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1026, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1055, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1170, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0954, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1102, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1016, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1007, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0940, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1102, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1106, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1092, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1007, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1030, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1011, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1126, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1083, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0936, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0987, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0946, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0951, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1101, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1177, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0968, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0975, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1087, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1071, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1125, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1021, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1124, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0959, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0997, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1058, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1073, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1100, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1138, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1030, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0945, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1021, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1143, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1048, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1053, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0997, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0950, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0955, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1025, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1128, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1081, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1114, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1110, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1038, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1024, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1091, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1085, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1104, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1086, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1002, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1043, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0997, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0945, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1085, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1099, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0987, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1140, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1024, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1011, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1024, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1038, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1149, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1038, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1070, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1043, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1038, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1043, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1111, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0950, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1052, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0918, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1061, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1019, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1050, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0960, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1083, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1079, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1147, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0987, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1147, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0937, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1083, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1119, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1019, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1064, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1055, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1101, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1123, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0946, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1100, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0991, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0951, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1096, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1019, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1086, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0991, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0991, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0991, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0960, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1086, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1068, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0908, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0906, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0896, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1018, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0951, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1018, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1054, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0955, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1139, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1135, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1135, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0937, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0937, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0965, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1085, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1170, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0956, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1054, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1026, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0947, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0933, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1013, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1067, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1062, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1026, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1080, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0951, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1021, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1053, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1062, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1027, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1084, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1097, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1071, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1030, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0951, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1185, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0921, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1070, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1048, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1145, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1070, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1074, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0960, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1052, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0933, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0938, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1048, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0965, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1007, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1021, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0921, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0955, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1113, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1008, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1100, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1113, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0950, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1121, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1063, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0943, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1004, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1025, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1100, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0995, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1107, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1026, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0913, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1120, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1116, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1004, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0966, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0985, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0921, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1102, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1007, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1011, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0951, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1072, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1016, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0991, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1038, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1024, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1067, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1081, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1004, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0951, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0987, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1123, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0961, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1004, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1055, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1083, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1081, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0963, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1145, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1063, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0976, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0965, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1028, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1083, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0926, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0930, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0902, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1140, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1053, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1027, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1003, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1063, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1139, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1029, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0955, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1008, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0991, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1038, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1050, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1063, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1011, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1087, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1100, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0991, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1011, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1024, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1160, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0954, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0971, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1095, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1007, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0991, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1024, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1099, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0965, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1119, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1086, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0959, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1133, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1053, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1016, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0945, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1073, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1008, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1064, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1065, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0981, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1135, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1016, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1002, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0998, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0974, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0991, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1072, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1002, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1060, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1002, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1101, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0951, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0976, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0968, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0997, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1129, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0989, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0993, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1003, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0952, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0954, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1061, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1075, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0940, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1099, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1063, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0942, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0975, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1043, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1097, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0959, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0984, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1055, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0898, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1092, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0952, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0990, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1066, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1018, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1070, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1074, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1062, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1060, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1066, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0977, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0924, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0995, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0967, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1025, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1055, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1136, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0913, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1008, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0919, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1058, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1127, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1072, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0937, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1065, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1053, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0990, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1030, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1150, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1018, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0962, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1013, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1100, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0917, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1074, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0931, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0923, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1080, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1026, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1115, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1084, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0961, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1021, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0930, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1079, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1008, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0993, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1004, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1089, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1016, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1011, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1013, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1066, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1003, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0918, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0952, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0943, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0974, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0997, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1129, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1025, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0965, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0934, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1011, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0941, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1048, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1091, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1048, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0929, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1160, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0980, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1110, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1085, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1116, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1079, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1018, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1125, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1002, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0971, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1086, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0949, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1043, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0950, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0979, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1016, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0924, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1154, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1102, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0979, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0937, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1002, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0972, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1064, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0985, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1099, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1004, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1099, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1112, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1002, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0932, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0974, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1105, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1063, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1025, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0922, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1094, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0975, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0975, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0974, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1062, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1074, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1002, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0932, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1066, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0952, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1048, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0903, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1008, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1028, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1060, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1055, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0977, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1067, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0997, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1043, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1011, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1081, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0906, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1063, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0947, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1029, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0976, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0995, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1021, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1080, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0937, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1146, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0953, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0979, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1097, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1029, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0981, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1053, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0985, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1062, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0958, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1067, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0984, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0937, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0989, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1062, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1070, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1087, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0951, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1004, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1083, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1071, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0979, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1079, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1008, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1028, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1018, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0959, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1038, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0959, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0967, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0995, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0934, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0898, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1127, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0985, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1025, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0980, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1067, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1013, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1083, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.numpy())\n",
    "\n",
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = label_encoder.inverse_transform(all_predictions)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3027656477438137\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
